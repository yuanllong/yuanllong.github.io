<!DOCTYPE html>
<html lang="zh-CN,en,default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"humble2967738843.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="08线性回归 8.1线性回归 如何在美国买房 看中一个房子，参观了解 估计一个价格，出价    房屋基本信息：  房屋实景：   房价预测  历史的房价走势：  当你以一定的价格购入本套房屋之后，过了一段时间，再次给出房价走势，就可以看出你的盈亏情况。   一个简化模型 假设1：影响房价的关键因素是卧室个数，卫生间个数和居住面积，记为：$x_1, x_2, x_3$     假设2：成交价是关键因">
<meta property="og:type" content="article">
<meta property="og:title" content="08线性回归">
<meta property="og:url" content="http://humble2967738843.github.io/2023/12/12/08-xian-xing-hui-gui/index.html">
<meta property="og:site_name" content="院龙">
<meta property="og:description" content="08线性回归 8.1线性回归 如何在美国买房 看中一个房子，参观了解 估计一个价格，出价    房屋基本信息：  房屋实景：   房价预测  历史的房价走势：  当你以一定的价格购入本套房屋之后，过了一段时间，再次给出房价走势，就可以看出你的盈亏情况。   一个简化模型 假设1：影响房价的关键因素是卧室个数，卫生间个数和居住面积，记为：$x_1, x_2, x_3$     假设2：成交价是关键因">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/tPoJxLu1haDlczS.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/G8lb3v2MTjiUFkp.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/iQoMejmu6ckIWVt.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/zZJpXMCyNceQ5dS.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/S4DWyRkCAedNTxK.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/I3yiWQ5vYeoMTkZ.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/IC5SVO2rBnqemTf.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/RItL3PfZVknXJpY.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/DW4uyxs8ChE5oqv.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/ozCe2PbAqRND61x.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/12/nzMLgJox6YaTkeb.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/13/4aWFywdeXGmxp59.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/2qSVmaTbBR1K5f9.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/WXuQLoEcINxZPvn.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/MZ9zkbDwBVvR17T.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/XCxtkbZ4BWr6l8n.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/TInKoBS5QPJAUWb.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/2UedgPGCbDfXn4B.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/TJ3Z4vCA5uglOBw.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/FA91vEV67NuJsxd.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/v7jeUiyugqz1YNG.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/XsUFn1y5zOHvgSD.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/xg674mtyRBDwVNT.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/YAUjywHJtiGIqza.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/haFO3GwWx8sfCHb.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/lvUeO86GtAfshwF.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/uYpaDe2cWtVzHr9.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/jsLdtpzMS7IPACZ.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/nALkb6Zu1ihVRDG.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/9SDstzekOTm8pGK.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/XEa1jy5OvfYgIMD.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/8wRQnexJV7UlpgP.png">
<meta property="og:image" content="https://s2.loli.net/2023/12/17/XuKPJTnZM2ve35O.png">
<meta property="article:published_time" content="2023-12-12T04:41:36.238Z">
<meta property="article:modified_time" content="2024-05-26T05:06:58.690Z">
<meta property="article:author" content="院龙">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/12/12/tPoJxLu1haDlczS.png">

<link rel="canonical" href="http://humble2967738843.github.io/2023/12/12/08-xian-xing-hui-gui/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>08线性回归 | 院龙</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><link rel="alternate" href="/atom.xml" title="院龙" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">院龙</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://humble2967738843.github.io/2023/12/12/08-xian-xing-hui-gui/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="院龙">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="院龙">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          08线性回归
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-12 12:41:36" itemprop="dateCreated datePublished" datetime="2023-12-12T12:41:36+08:00">2023-12-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-05-26 13:06:58" itemprop="dateModified" datetime="2024-05-26T13:06:58+08:00">2024-05-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="08线性回归"><a href="#08线性回归" class="headerlink" title="08线性回归"></a>08线性回归</h1><p><img src="https://s2.loli.net/2023/12/12/tPoJxLu1haDlczS.png" alt="image-20231212124321900"></p>
<h2 id="8-1线性回归"><a href="#8-1线性回归" class="headerlink" title="8.1线性回归"></a>8.1线性回归</h2><ul>
<li>如何在美国买房<ul>
<li>看中一个房子，参观了解</li>
<li>估计一个价格，出价</li>
</ul>
</li>
</ul>
<p>房屋基本信息：</p>
<p><img src="https://s2.loli.net/2023/12/12/G8lb3v2MTjiUFkp.png" alt="image-20231212124510969"></p>
<p>房屋实景：</p>
<p><img src="https://s2.loli.net/2023/12/12/iQoMejmu6ckIWVt.png" alt="image-20231212124539159"></p>
<ul>
<li>房价预测</li>
</ul>
<p>历史的房价走势：</p>
<p><img src="https://s2.loli.net/2023/12/12/zZJpXMCyNceQ5dS.png" alt="image-20231212124737102"></p>
<p>当你以一定的价格购入本套房屋之后，过了一段时间，再次给出房价走势，就可以看出你的盈亏情况。</p>
<p><img src="https://s2.loli.net/2023/12/12/S4DWyRkCAedNTxK.png" alt="image-20231212124913782"></p>
<ul>
<li>一个简化模型</li>
<li>假设1：影响房价的关键因素是卧室个数，卫生间个数和居住面积，记为：$x_1, x_2, x_3$ </li>
</ul>
<p><img src="https://s2.loli.net/2023/12/12/I3yiWQ5vYeoMTkZ.png" alt="image-20231212125228395"></p>
<ul>
<li>假设2：成交价是关键因素的加权和</li>
</ul>
<script type="math/tex; mode=display">
y = w_1x_1 + w_2x_2 + w_3x_3 + b</script><p>权重和偏差的实际值在后面决定</p>
<ul>
<li>线性模型<ul>
<li>给定 n 维输入 $\boldsymbol {x} = [x_1,x_2,…, x_n]^T$</li>
<li>线性模型有一个 n 维权重和一个标量偏差</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol {w} = [w_1, w_2, ..., w_n]^T, b</script><ul>
<li>输出是输入的加权和</li>
</ul>
<script type="math/tex; mode=display">
y = w_1x_1 + w_2x_2 + ... + w_nx_n + b</script><p>向量版本：$y = &lt;\boldsymbol {w}, \boldsymbol {x}&gt; + b$</p>
<ul>
<li><strong>线性模型可以看作是单层的神经网络</strong></li>
</ul>
<p><img src="https://s2.loli.net/2023/12/12/IC5SVO2rBnqemTf.png" alt="image-20231212125932995"></p>
<ul>
<li>神经网络源于神经科学</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/12/RItL3PfZVknXJpY.png" alt="image-20231212130138271"></p>
<ul>
<li>衡量预估质量<ul>
<li>比较真实值和预估值，例如房屋售价和估价</li>
<li>假设 $y$ 是真实值，$\hat {y}$ 是估计值，我们可以比较</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
l(y, \hat{y}) = 1/2(y - \hat{y})^2</script><p>这个叫做平方损失</p>
<ul>
<li>训练数据<ul>
<li>收集一些数据点来决定参数值（权重和偏差），例如过去6个卖的房子</li>
<li>这被称之为训练数据</li>
<li>通常越多越好</li>
<li>假设我们有 n 个样本，记</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol {X} = \left[ \boldsymbol {x_1}, \boldsymbol {x_2}, ..., \boldsymbol {x_n} \right]^T \\
\boldsymbol {y} = \left[ {y_1}, {y_2}, ..., {y_n} \right]^T</script><ul>
<li>参数学习<ul>
<li>训练损失</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
l(\boldsymbol {X}, \boldsymbol {y}, \boldsymbol {w}, b) = 1/2n \sum_{i=1}^n (y_i - <\boldsymbol {x_i}, \boldsymbol {w}> - b)^2 \\ = 1/2n ||\boldsymbol {y} - \boldsymbol {X}\boldsymbol {w} - b||^2</script><ul>
<li>最小化损失来学习参数</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol {w}^*, \boldsymbol {b}^* = arg \space min_{\boldsymbol {w}, b} \space l(\boldsymbol {X}, \boldsymbol {y}, \boldsymbol {w}, b)</script><ul>
<li>显式解<ul>
<li>将偏差加入权重 $\boldsymbol {X} \longleftarrow [\boldsymbol {X}, \boldsymbol {1}] \space \boldsymbol {w} \longleftarrow [\boldsymbol {w}, b]^T$</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
l(\boldsymbol {X}, \boldsymbol {y}, \boldsymbol {w} = 1/2n ||\boldsymbol {y} - \boldsymbol {X}\boldsymbol {w}||^2 \space ) \space \frac{\partial}{\partial \boldsymbol {w}}l(\boldsymbol {X}, \boldsymbol {y}, \boldsymbol {w}) \\
=1/n (\boldsymbol {y} - \boldsymbol {X}\boldsymbol {w})^T\boldsymbol {X}</script><ul>
<li>损失是凸函数（<strong>意味着最优解就在梯度等于0的地方</strong>），所以满足最优解</li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial}{\partial w} l(\boldsymbol {X}, \boldsymbol {y}, \boldsymbol {w}) = 0 \\
<=> 1/n(\boldsymbol {y} - \boldsymbol {X}\boldsymbol {w})^T\boldsymbol {X} = 0 \\
<=> \boldsymbol {W}^* = (\boldsymbol {X}^T\boldsymbol {X})^{-1}\boldsymbol {X}\boldsymbol {y}</script><ul>
<li>总结<ul>
<li>线性回归是对 n 维输入的加权，外加偏差</li>
<li>使用平方损失来衡量预测值于真实值的差异</li>
<li>线性回归有显示解</li>
<li>线性回归可以看作是单层神经网络</li>
</ul>
</li>
</ul>
<h2 id="8-2基础优化算法"><a href="#8-2基础优化算法" class="headerlink" title="8.2基础优化算法"></a>8.2基础优化算法</h2><p><img src="https://s2.loli.net/2023/12/12/DW4uyxs8ChE5oqv.png" alt="image-20231212223951202"></p>
<ul>
<li>梯度下降（<strong>当一个模型没有显式解</strong>）<ul>
<li>挑选一个初始值 $\boldsymbol {w}_0$</li>
<li>重复迭代参数 t = 1, 2, 3</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol {w}_t = \boldsymbol {w}_{t-1} - \eta \frac{\partial \phi }{\partial \boldsymbol {w}_{t-1}}</script><ul>
<li><p>沿着梯度方向将增加损失函数值</p>
</li>
<li><p>学习率：步长的超参数</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/12/ozCe2PbAqRND61x.png" alt="二次函数等高线"></p>
<p>分析这个例子，<strong>二次函数的等高线如上，首先挑选一个初始值 $\boldsymbol {w}_0$ ，然后计算它此处的梯度，也就是当前点处函数增长最快的方向，那么负梯度，就是函数下降最快的方向，我们要求出那个最优解，也就是谷底的位置，就要沿着某条路线不断接近这个最优点，而每一处的梯度为我们指明了方向。</strong></p>
<ul>
<li>如何选择学习率</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/12/nzMLgJox6YaTkeb.png" alt="image-20231212225822368"></p>
<ul>
<li>小批量随机梯度下降<ul>
<li>在整个训练集上计算梯度太贵了<ul>
<li>一个深度神经网络模型可能需要数分钟至数小时</li>
</ul>
</li>
<li>我们可以随机采样 b 个样本 $i_1, i_2, …, i_b$ 来近似损失</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">
\frac{1}{b} \sum_{i \in I_b} l(\boldsymbol {X}_i, y_i, \boldsymbol {w})</script><ul>
<li>b是批量大小，另一个重要的超参数</li>
</ul>
<ul>
<li>选择批量大小<ul>
<li>不能太小：每次计算量太小，不适合并行最大利用计算资源</li>
<li>不能太大：内存消耗增加，浪费计算，例如：如果所有样本嗾使相同的</li>
</ul>
</li>
</ul>
<ul>
<li>总结<ul>
<li><strong>梯度下降通过不断沿着繁体都方向更新参数求解</strong></li>
<li><strong>小批量随机梯度下降是深度学习的求解算法</strong></li>
<li><strong>两个重要的超参数是批量大小和学习率</strong></li>
</ul>
</li>
</ul>
<h2 id="8-3线性回归的从零开始实现"><a href="#8-3线性回归的从零开始实现" class="headerlink" title="8.3线性回归的从零开始实现"></a>8.3线性回归的从零开始实现</h2><ul>
<li>我们将从零开始实现整个方法，包括数据流水线、模型、损失函数和小批量随机梯度下降优化器</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/13/4aWFywdeXGmxp59.png" alt="image-20231213125158033"></p>
<ul>
<li>根据带有噪声的线性模型构造一个人造数据集，我们使用线性模型参数$\boldsymbol {w} = [2, -3.4]^T$、$b = 4.2$ 和噪声$\xi$生成数据集及其标签：</li>
</ul>
<script type="math/tex; mode=display">
\boldsymbol {y} = \boldsymbol {X}\boldsymbol {w} + b + \xi</script><p><img src="https://s2.loli.net/2023/12/17/2qSVmaTbBR1K5f9.png" alt="image-20231217121341803"></p>
<p><img src="https://s2.loli.net/2023/12/17/WXuQLoEcINxZPvn.png" alt="image-20231217121408819"></p>
<p>参考</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41898018/article/details/119244914">torch.normal()的用法</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/didi_ya/article/details/121158666">PyTorch疑难杂症（1）——torch.matmul()函数用法总结</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_28618765/article/details/78083895">Python numpy函数：reshape（）</a></p>
<p>X 的产生：从均值为 0 ，方差为 1 的分布，也就是正态分布中进行采样，行数是 num_examples ， 列数是 true_w 的列数，也就是特征数量。</p>
<p>y 是 X 和 w 进行矩阵相乘后，加上偏置 b 后实现的，也就是先将 [1000, 2] 的矩阵和 [1, 2] 的矩阵进行矩阵的相乘（<strong>使用了广播机制</strong>）。</p>
<p> y 添加噪音的方式是噪音元素和 y 元素的元素级相加。</p>
<ul>
<li><code>features</code>中的每一行都包含一个二维数据样本，<code>labels</code>中的每一行都包含一位标签值（一个标量）</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/MZ9zkbDwBVvR17T.png" alt="image-20231217123328347"></p>
<ul>
<li>通过生成第二个特征<code>features[:, 1]</code>和<code>labels</code>的散点图， 可以直观观察到两者之间的线性关系。</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/XCxtkbZ4BWr6l8n.png" alt="image-20231217124441242"></p>
<ul>
<li>在下面的代码中，我们[<strong>定义一个<code>data_iter</code>函数， 该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为<code>batch_size</code>的小批量</strong>]。 每个小批量包含一组特征和标签。</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/TInKoBS5QPJAUWb.png" alt="image-20231217130008390"></p>
<p><a target="_blank" rel="noopener" href="https://www.runoob.com/python/func-number-shuffle.html">Python shuffle() 函数</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41289353/article/details/125224049">python中yield的用法详解——最简单，最清晰的解释</a></p>
<p><img src="https://s2.loli.net/2023/12/17/2UedgPGCbDfXn4B.png" alt="image-20231217130201345"></p>
<ul>
<li>定义初始化模型参数</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/TJ3Z4vCA5uglOBw.png" alt="image-20231217130249921"></p>
<ul>
<li>定义模型</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/FA91vEV67NuJsxd.png" alt="image-20231217130350962"></p>
<ul>
<li>定义损失函数</li>
</ul>
<p>因为需要计算损失函数的梯度，所以我们应该先定义损失函数。 这里我们使用 :numref:<code>sec_linear_regression</code>中描述的平方损失函数。 在实现中，我们需要将真实值<code>y</code>的形状转换为和预测值<code>y_hat</code>的形状相同。</p>
<p><img src="https://s2.loli.net/2023/12/17/v7jeUiyugqz1YNG.png" alt="image-20231217130607942"></p>
<ul>
<li>定义优化算法</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/XsUFn1y5zOHvgSD.png" alt="image-20231217131537328"></p>
<ul>
<li>训练过程</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/xg674mtyRBDwVNT.png" alt="image-20231217131731388"></p>
<ul>
<li><strong>比较真实参数和通过训练学到的参数来评估训练的成功程度</strong></li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/YAUjywHJtiGIqza.png" alt="image-20231217132033441"></p>
<h2 id="8-4线性回归的简洁实现"><a href="#8-4线性回归的简洁实现" class="headerlink" title="8.4线性回归的简洁实现"></a>8.4线性回归的简洁实现</h2><ul>
<li>通过使用深度学习框架来简洁地实现 线性回归模型 生成数据集</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/haFO3GwWx8sfCHb.png" alt="image-20231217155518330"></p>
<ul>
<li>调用框架中现有的 API 来读取数据</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/lvUeO86GtAfshwF.png" alt="image-20231217155711824"></p>
<p>我们可以这样使用数据集，迭代方式是：</p>
<p><img src="https://s2.loli.net/2023/12/17/uYpaDe2cWtVzHr9.png" alt="image-20231217155833142"></p>
<ul>
<li>使用框架的预定义好的层</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/jsLdtpzMS7IPACZ.png" alt="image-20231217155906459"></p>
<p>可以直接使用 <code>PyTorch</code>中的 <code>nn</code>模块，里面有神经网络的容器函数 <code>nn.Sequential()</code>，里面填入一个<code>nn.Linear(2, 1)</code> 等价于我们的线性函数，输入维度为 2 输出维度是 1。</p>
<p><img src="https://s2.loli.net/2023/12/17/nALkb6Zu1ihVRDG.png" alt="image-20231217160340171"></p>
<ul>
<li>计算均方误差使用的是 <code>MSELoss</code>类，也称为平方范数</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/9SDstzekOTm8pGK.png" alt="image-20231217160520473"></p>
<ul>
<li>实例化<code>SGD</code>实例</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/XEa1jy5OvfYgIMD.png" alt="image-20231217160618366"></p>
<ul>
<li>训练过程代码于我们从零开始的实现时所做的非常相似</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/8wRQnexJV7UlpgP.png" alt="image-20231217160836903"></p>
<ul>
<li>比较误差</li>
</ul>
<p><img src="https://s2.loli.net/2023/12/17/XuKPJTnZM2ve35O.png" alt="image-20231217160946721"></p>
<h2 id="8-5QA"><a href="#8-5QA" class="headerlink" title="8.5QA"></a>8.5QA</h2>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/12/11/07-zi-dong-qiu-dao/" rel="prev" title="07自动求导">
      <i class="fa fa-chevron-left"></i> 07自动求导
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/12/17/09-softmax-hui-gui-sun-shi-han-shu-tu-pian-fen-lei-shu-ju-ji/" rel="next" title="09 Softmax 回归 + 损失函数 + 图片分类数据集">
      09 Softmax 回归 + 损失函数 + 图片分类数据集 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#08%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.</span> <span class="nav-text">08线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#8-1%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.1.</span> <span class="nav-text">8.1线性回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-2%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">8.2基础优化算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-3%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.3.</span> <span class="nav-text">8.3线性回归的从零开始实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-4%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.4.</span> <span class="nav-text">8.4线性回归的简洁实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-5QA"><span class="nav-number">1.5.</span> <span class="nav-text">8.5QA</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="院龙"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">院龙</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">院龙</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"live2d-widget-model-chitose"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
